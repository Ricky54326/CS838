{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('out.csv', usecols=['id','title','artist','year'])\n",
    "df.id = df.id.drop_duplicates()\n",
    "df = df[np.isfinite(df['id']) == True]\n",
    "df = df[np.isfinite(df['year']) == True]\n",
    "df.year = df.year.astype(int)\n",
    "df = df[df['title'].astype(str) != \" \"]\n",
    "df = df[df['artist'].astype(str) != \" \"]\n",
    "df = df[(df['year'] >= 1999 ) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df[col].astype(str).str.lower() for col in df.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('d_table.csv', index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('pitchfork_reviews.csv', usecols =['id', 'title','artist','year'])\n",
    "df.id = df.id.drop_duplicates()\n",
    "df = df[np.isfinite(df['id']) == True]\n",
    "df = pd.concat([df[col].astype(str).str.lower() for col in df.columns], axis=1)\n",
    "df.to_csv('p_table.csv', index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = em.read_csv_metadata('p_table.csv', key='reviewid')\n",
    "B = em.read_csv_metadata('d_table.csv', key='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ob = em.OverlapBlocker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = ob.block_tables(A, B, 'title', 'title', word_level=True, overlap_size=3, \n",
    "                    l_output_attrs=['title', 'artist', 'year'], \n",
    "                    r_output_attrs=['title', 'artist', 'year'],\n",
    "                    show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ab = em.AttrEquivalenceBlocker()\n",
    "D = ab.block_candset(C, 'title', 'title', show_progress=False)\n",
    "D.to_csv('tuples_after_blocking', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = D.sample(n = 3000)\n",
    "D.to_csv('sample.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2075\n",
       "0     925\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeled_tuples.csv')\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = em.read_csv_metadata('labeled_tuples.csv', \n",
    "                         key='_id',\n",
    "                         ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable_reviewid', fk_rtable='rtable_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IJ = em.split_train_test(S, train_proportion=0.6, random_state=0)\n",
    "I = IJ['train']\n",
    "J = IJ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           title_title_jac_qgm_3_qgm_3\n",
       "1       title_title_cos_dlm_dc0_dlm_dc0\n",
       "2       title_title_jac_dlm_dc0_dlm_dc0\n",
       "3                       title_title_mel\n",
       "4                  title_title_lev_dist\n",
       "5                   title_title_lev_sim\n",
       "6                       title_title_nmw\n",
       "7                        title_title_sw\n",
       "8         artist_artist_jac_qgm_3_qgm_3\n",
       "9     artist_artist_cos_dlm_dc0_dlm_dc0\n",
       "10    artist_artist_jac_dlm_dc0_dlm_dc0\n",
       "11                    artist_artist_mel\n",
       "12               artist_artist_lev_dist\n",
       "13                artist_artist_lev_sim\n",
       "14                    artist_artist_nmw\n",
       "15                     artist_artist_sw\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = em.get_features_for_matching(A, B)\n",
    "F.feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='label',\n",
    "                            show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(pd.notnull(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H = em.impute_table(H, exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], strategy='mean')\n",
    "#K.to_csv('set_J.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(pd.notnull(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000023593574400&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988048</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>0.995652</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000023588605BE0&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996016</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.993919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000023593574978&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996255</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.997699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x00000235886052E8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988048</td>\n",
       "      <td>0.992218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.990793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000023588605BA8&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996016</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.995417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x00000235886059B0&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992032</td>\n",
       "      <td>0.996109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.993122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3        LinReg   \n",
       "4        LogReg   \n",
       "5            NB   \n",
       "\n",
       "                                                                                Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x0000023593574400>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x0000023588605BE0>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x0000023593574978>   \n",
       "3  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x00000235886052E8>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x0000023588605BA8>   \n",
       "5          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x00000235886059B0>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Mean score  \n",
       "0          5  0.988048  0.996109  0.995652  0.992509  0.988679    0.992200  \n",
       "1          5  0.996016  0.996109  1.000000  0.985019  0.992453    0.993919  \n",
       "2          5  0.996016  1.000000  1.000000  0.996255  0.996226    0.997699  \n",
       "3          5  0.988048  0.992218  1.000000  0.985019  0.988679    0.990793  \n",
       "4          5  0.996016  0.996109  1.000000  0.992509  0.992453    0.995417  \n",
       "5          5  0.992032  0.996109  1.000000  0.985019  0.992453    0.993122  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'],\n",
    "        k=5,\n",
    "        target_attr='label', metric='recall', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "       target_attr='label')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='label', show_progress=False)\n",
    "\n",
    "# Predict on L \n",
    "predictions = dt.predict(table=L, exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 98.88% (798/807)\n",
      "Recall : 99.13% (798/805)\n",
      "F1 : 99.01%\n",
      "False positives : 9 (out of 807 positive predictions)\n",
      "False negatives : 7 (out of 393 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 97.92% (800/817)\n",
      "Recall : 99.38% (800/805)\n",
      "F1 : 98.64%\n",
      "False positives : 17 (out of 817 positive predictions)\n",
      "False negatives : 5 (out of 383 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "svm.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "       target_attr='label')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='label', show_progress=False)\n",
    "\n",
    "# Predict on L \n",
    "predictions = svm.predict(table=L, exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 99.38% (800/805)\n",
      "Recall : 99.38% (800/805)\n",
      "F1 : 99.38%\n",
      "False positives : 5 (out of 805 positive predictions)\n",
      "False negatives : 5 (out of 395 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "rf.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "       target_attr='label')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='label', show_progress=False)\n",
    "\n",
    "# Predict on L \n",
    "predictions = rf.predict(table=L, exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 99.5% (796/800)\n",
      "Recall : 98.88% (796/805)\n",
      "F1 : 99.19%\n",
      "False positives : 4 (out of 800 positive predictions)\n",
      "False negatives : 9 (out of 400 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "lg.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "       target_attr='label')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='label', show_progress=False)\n",
    "\n",
    "# Predict on L \n",
    "predictions = lg.predict(table=L, exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 99.5% (797/801)\n",
      "Recall : 99.01% (797/805)\n",
      "F1 : 99.25%\n",
      "False positives : 4 (out of 801 positive predictions)\n",
      "False negatives : 8 (out of 399 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "ln.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "       target_attr='label')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='label', show_progress=False)\n",
    "\n",
    "# Predict on L \n",
    "predictions = ln.predict(table=L, exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = em.NBMatcher(name='NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 99.5% (797/801)\n",
      "Recall : 99.01% (797/805)\n",
      "F1 : 99.25%\n",
      "False positives : 4 (out of 801 positive predictions)\n",
      "False negatives : 8 (out of 399 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "nb.fit(table=H, \n",
    "       exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "       target_attr='label')\n",
    "\n",
    "# Convert J into a set of feature vectors using F\n",
    "L = em.extract_feature_vecs(J, feature_table=F,\n",
    "                            attrs_after='label', show_progress=False)\n",
    "\n",
    "# Predict on L \n",
    "predictions = nb.predict(table=L, exclude_attrs=['_id', 'ltable_reviewid', 'rtable_id', 'label'], \n",
    "              append=True, target_attr='predicted', inplace=False)\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
